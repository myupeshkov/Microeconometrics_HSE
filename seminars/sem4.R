# --------
# Потанин Богдан Станиславович
# Микроэконометрика в R :)
# Семинар 4. Тестирование гипотез о распределении случайных
#            ошибок и минимум хи-квадрат метод
# --------

# Отключим scientific notation
options(scipen = 999)

# Симулируем данные, содержащую информацию
# о характеристиках заемщика, а также о том,
# наступил ли у него дефолт по ипотеке.
# Все переменные измерены в условных единицах
set.seed(12345)                                            # для воспроизводимости
n <- 10000                                                 # число индивидов в выборке
h <- data.frame(ind = rep(1:n))                            # датафрейм для хранения данных
h$inc <- runif(n, 0, 1)                                    # доход в условных единицах
h$pay <- runif(n, 0, 1)                                    # ежемесячный платеж
h$age <- runif(n, 0, 1)                                    # возраст
h$ins <- rbinom(n, 1, 0.7)                                 # факт наличия страховки
h$chl <- rbinom(n, 1, 0.6)                                 # факт наличия детей

ber <- rbinom(n, size = 1, prob = 0.7)                     # случайная ошибка
xi1 <- rt(n, 5)                                            # из смеси распределений
xi2 <- rt(n, 5)                                            # Стьюдента
eps <- ber * (xi1 - 3) + 
  (1 - ber) * (xi2 + 3)
eps <- (eps + 1.199419) / 3.037912                         # стандартизация для
# удобства
plot(density(eps))

beta <- c(0.6, -3, 2, -5, 3.5, -0.8, 0, 0.8)               # оцениваемые регрессионные 
# коэффициенты


def_li <- beta[1] +                                        # линейный индекс,
  beta[2] * h$inc +                                # отражающий вклад наблюдаемых
  beta[3] * h$pay +                                # факторов в вероятность дефолта
  beta[4] * h$age +
  beta[5] * h$age ^ 2 +                                            
  beta[6] * h$ins +                          
  beta[7] * h$chl +
  beta[8] * (h$chl * h$inc)

def_star <- def_li + eps                                   # латентная переменная,
# отражающая склонность
# к дефолту
h$def <- as.numeric(def_star >= 0)                         # наблюдаемое значение переменной
mean(h$def)                                                # доля дефолтов

h$ind <- NULL                                              # уберем индексы
head(h)                                                    # посмотрим на данные

#---------------------------------------------------
# Часть 1. Тестирование гипотезы о нормальном
#          распределении случайных ошибок
#---------------------------------------------------

library("numDeriv")                                        # численно дифференцирование

# Оценим пробит модель
model.probit <- glm(formula = def ~ inc + pay +            # оцениваем модель
                      age + I(age ^ 2) +
                      ins + chl +
                      I(chl * inc),
                    data = h,                                  
                    family = binomial(link = "probit")) 

# Запишем функцию правдоподобия
# для модели со случайно ошибкой
# из распределения Пирсона
ProbitLnLExtended <- function(par,                       # вектор значений параметров
                              y,                         # зависимая переменная 
                              X,                         # матрица независимых переменных
                              is_aggregate = TRUE)       # при TRUE возвращаем логарифм
  # функции правдоподобия, а при
  # FALSE возвращаем вектор вкладов
{
  beta <- matrix(par[-c(1, 2)], ncol = 1)                # вектор beta коэффициентов и
  t <- matrix(par[c(1, 2)], ncol = 1)                    # вектор дополнительных параметров  
  # переводим в матрицу с одним столбцом
  y_li <- X %*% beta                                     # оценка линейного индекса
  y_est <- y_li + t[1] * y_li ^ 2 +                      # оценка математического ожидания 
    t[2] * y_li ^ 3                        # латентной переменной
  
  n_obs <- nrow(X)                                       # количество наблюдений
  
  L_vec <- matrix(NA, nrow = n_obs,                      # вектор столбец вкладов наблюдений
                  ncol = 1)                              # в функцию правдоподобия
  
  is_y_0 <- (y == 0)                                     # вектор условий (y = 0)
  is_y_1 <- (y == 1)                                     # вектор условий (y = 1)
  
  L_vec[is_y_1] <- pnorm(y_est[is_y_1])                  # вклад наблюдений для которых yi = 1
  L_vec[is_y_0] <- 1 - pnorm(y_est[is_y_0])              # вклад наблюдений для которых yi = 0
  
  lnL_vec <- log(L_vec)                                  # логарифмы вкладов
  
  if(!is_aggregate)                                      # возвращаем вклады
  {                                                      # при необходимости
    return(lnL_vec)
  }
  
  lnL <- sum(lnL_vec)                                    # логарифм функции правдоподобия
  
  return(lnL)
}
# Воспользуемся созданной функцией
# Оценки модели при справедливом ограничении,
# накладываемом нулевой гипотезой
beta.est <- coef(model.probit)                           # достаем оценки из обычной пробит
beta.R <- c(0, 0, beta.est)                              # модели и приравниваем значения
names(beta.R)[c(1, 2)] <- c("t1", "t2")                  # дополнительных параметров к значениям,
# предполагаемым нулевой гипотезой
# Создадим матрицу регрессоров
X.mat <- as.matrix(model.frame(model.probit))            # достаем датафрейм с регрессорами и
X.mat[, 1] <- 1                                          # первращаем его в матрицу, а также
colnames(X.mat)[1] <- "Intercept"                        # заменяем зависимую переменную на константу
head(X.mat, 5)
# Применим функцию
lnL.R <- ProbitLnLExtended(beta.R, h$def, X.mat)         # считаем логарифм функции правоподобия
# при ограничениях, совпадающую с логарифмом
# функции правдоподобия обычной пробит модели
lnL.R.grad <- grad(func = ProbitLnLExtended,             # считаем градиент данной функции
                   x = beta.R,                           # численным методом
                   y = h$def, 
                   X = X.mat)
lnL.R.grad <- matrix(lnL.R.grad, ncol = 1)               # градиент как матрица с одним столбцом
lnL.R.Jac <- jacobian(func = ProbitLnLExtended,          # считаем Якобин данной функции
                      x = beta.R,                        # численным методом
                      y = h$def, 
                      X = X.mat,
                      is_aggregate = FALSE)
# Реализуем тест
LM.value.1 <- t(lnL.R.grad) %*%                          # считаем статистику теста
  solve(t(lnL.R.Jac) %*% lnL.R.Jac) %*%      # множителей Лагранжа
  lnL.R.grad
p.value_1 <- 1 - pchisq(LM.value.1, df = 2)              # рассчитываем p-value теста
# множителей Лагранжа

# С использованием регрессии на единицы

# Достанем датафрейм, содержащий
# переменные модели
d <- model.frame(model.probit)                           # все переменные

# Рассчитаем предварительные величины
y.li.est <- predict(model.probit)                        # оценка линейного индекса                                     
F.est <- pnorm(y.li.est)                                 # функции от линейного           
f.est <- dnorm(y.li.est)                                 # индекса

# Вычислим обобщенные остатки
gr <- ((d[, 1] - F.est) /                                # обобщенный остаток
         (F.est * (1 - F.est))) * f.est

# Считаем производные по коэффициентам
d_beta <- apply(X.mat, 2, function(x)                    # производные по
{                              # регресcионным коэффициентам
  x * gr
})
d_t1 <- (gr * y.li.est ^ 2)                              # производная по t1
d_t2 <- (gr * y.li.est ^ 3)                              # производная по t2

# Сравним аналитические и численные производные
grad_df <- data.frame("Numeric" = lnL.R.grad,
                      "Analytical" = colSums(cbind(d_t1, 
                                                   d_t2, 
                                                   d_beta)))
rownames(grad_df) <- c("t1", "t2", colnames(X.mat))
print(grad_df)

# Проводим LM тест
n <- nrow(d)                                             # число наблюдений
LM_df <- data.frame("my_ones" = rep(1, n),               # вектор из единиц 
                    "d_" = d_beta,
                    d_t1, d_t2)          
head(LM_df, 5)
ones_regression <- summary(lm(my_ones ~. + 0,            # регрессия на вектор единиц без константы
                              data = LM_df))       
R2 <- ones_regression$r.squared                          # коэффициент детерминации регрессии
LM_value_2 <- R2 * n                                     # LM статистика
p.value_2 <- 1 - pchisq(q = LM_value_2, 
                        df = 2)

# Сравним полученные результаты и убедимся,
# что они полностью совпадают
c(LM.value.1, LM_value_2)                                # сравниваем статистики
c(p.value_1, p.value_2)                                  # сравниваем p-value

#---------------------------------------------------
# Часть 2. Выбор между моделями бинарного выбора
#          с различным распределением случайных
#          ошибок на основе информационных
#          критериев
#---------------------------------------------------

# Оценим несколько моделей с альтернативным
# распределением случайных ошибок

# Логистическое распределение
model.logit <- glm(formula = def ~ inc + pay +
                     age + I(age ^ 2) +
                     ins + chl +
                     I(chl * inc),
                   data = h,                                  
                   family = binomial(link = "logit")) 
summary(model.logit)

# Распределение Коши
model.cauchit <- glm(formula = def ~ inc + pay +
                       age + I(age ^ 2) +
                       ins + chl +
                       I(chl * inc),
                     data = h,                                  
                     family = binomial(link = "cauchit")) 
summary(model.cauchit)

# Сравним модели по информационным 
# критериям AIC и BIC
# AIC
AIC_probit <- AIC(model.probit)
AIC_logit <- AIC(model.logit)
AIC_cauchit <- AIC(model.cauchit)
# BIC
BIC_probit <- BIC(model.probit)
BIC_logit <- BIC(model.logit)
BIC_cauchit <- BIC(model.cauchit)
# сравнение
IC_df <- data.frame("AIC" = c(AIC_probit, 
                              AIC_logit, 
                              AIC_cauchit),
                    "BIC" = c(BIC_probit, 
                              BIC_logit, 
                              BIC_cauchit))
rownames(IC_df) <- c("Normal", 
                     "Logistic", 
                     "Cauchit")
print(IC_df)

# ЗАДАНИЯ (* - непросто, ** - сложно, *** - брутально)
# 2.1.    Удалите переменные на возраст и проверьте, какая
#         из моделей окажется предпочтительней согласно
#         критериям AIC и BIC
# 2.2.    В соответствии с информационными критериями AIC и BIC
#         найдите наилучшую модель с гетероскедастичной случайной
#         ошибкой, дисперсия которой зависит от дохода и возраста, 
#         рассмотрев стандартное нормальное и логистическое
#         распределения

#---------------------------------------------------
# Часть 3. Минимум Хи-квадрат метод
#---------------------------------------------------

set.seed(123)                                            # для воспроизводимости

n <- 10000                                               # число наблюдений 

# Создадим несколько переменных,
# характеризующих индивида
male <- rbinom(n, 1, 0.6)                                # переменная на пол
u_rv <- runif(n)                                         # вспомогательная переменная
higher_educ <- u_rv > 0.8                                # высшее образование
basic_educ <- (u_rv >= 0.2) & (u_rv <= 0.8)              # среднее образование
no_educ <- (u_rv < 0.2)                                  # нет образования

# Создадим сгруппированные переменные
male_higher <- male & higher_educ                        # мужчины с высшим образованием
male_basic <- male & basic_educ                          # мужчины со средним образованием
male_no <- male & no_educ                                # мужчины без образования
female_higher <- !male & higher_educ                     # женщины с высшим образованием
female_basic <- !male & basic_educ                       # женщины со средним образованием
female_no <- !male & no_educ                             # женщины без образования

# Зададим имена группам
group_names <- c("male_higher", "male_basic",
                 "male_no", "female_higher",
                 "female_basic", "female_no")

# Рассчитаем размеры групп
group_n <- c(sum(male_higher), sum(male_basic),
             sum(male_no), sum(female_higher),
             sum(female_basic), sum(female_no))
names(group_n) <- group_names

# Симулируем случайную ошибку из
# распределения Cтьюдента
df <- 5
eps <- rt(n, df)

# Создадим латентную переменную
# на факт занятости индивида
beta <- c(-2, 2, 1.5, 1)
work_li <- beta[1] * male + beta[2] * higher_educ +
  beta[3] * basic_educ + beta[4] * no_educ
work_latent <- work_li + eps
work <- as.numeric(work_latent >= 0)

# Зададим вероятности занятости
# для каждой из групп
p_male_higher <- pt(work_li[male_higher][1], df)         # мужчины с высшим образованием
p_male_basic <- pt(work_li[male_basic][1], df)           # мужчины со средним образованием
p_male_no <- pt(work_li[male_no][1], df)                 # мужчины без образования
p_female_higher <- pt(work_li[female_higher][1], df)     # женщины с высшим образованием
p_female_basic <- pt(work_li[female_basic][1], df)       # женщины со средним образованием
p_female_no <- pt(work_li[female_no][1], df)             # женщины без образования
p <- c(p_male_higher, 
       p_male_basic,
       p_male_no,
       p_female_higher,
       p_female_basic,
       p_female_no)
names(p) <- group_names

# Оценим вероятности занятости
p_male_higher_est <- mean(work[male_higher])             # мужчины с высшим образованием
p_male_basic_est <- mean(work[male_basic])               # мужчины со средним образованием
p_male_no_est <- mean(work[male_no])                     # мужчины без образования
p_female_higher_est <- mean(work[female_higher])         # женщины с высшим образованием
p_female_basic_est <- mean(work[female_basic])           # женщины со средним образованием 
p_female_no_est <- mean(work[female_no])                 # женщины без образования
p_hat <- c(p_male_higher_est, 
           p_male_basic_est,
           p_male_no_est,
           p_female_higher_est,
           p_female_basic_est,
           p_female_no_est)
names(p_hat) <- group_names

# Сравним истинные вероятности и их оценки
rbind(p, p_hat)

# Оценим линейное уравнение при помощи МНК
X <- matrix(c(1, 1, 0, 0,
              1, 0, 1, 0,
              1, 0, 0, 1,
              0, 1, 0, 0,
              0, 0, 1, 0,
              0, 0, 0, 1),
            ncol = 4,
            byrow = TRUE)
colnames(X) <- c("male", "higher", "basic", "no")

# Применим обычный МНК с правильной
# квантильной функцией
model_lm <- lm(qt(p_hat, df) ~ X + 0)

# Сравним предсказанные вероятности
p_hat_lm <- pt(predict(model_lm), df)
rbind(p, p_hat, p_hat_lm)

# Сравним коэффициенты
beta_lm <- model_lm$coefficients
data.frame("Estimates" = beta_lm, 
           "True" = beta)

# Применим МНК с весами

# Считаем веса
p_weight <- sqrt(p_hat * (1 - p_hat) / group_n) * 
  grad(qt, p_hat, df = df)

# Применяем МНК с весами
model_weight <- lm(qt(p_hat, df) ~ X + 0, 
                   weights = p_weight)

# Сравним предсказанные вероятности
p_hat_weight <- pt(predict(model_weight), df)
rbind(p, p_hat, p_hat_lm, p_hat_weight)

# Сравним коэффициенты
beta_weight <- model_weight$coefficients
data.frame("LS" = beta_lm, 
           "LS Weights" = beta_weight,
           "True" = beta)

# Применим двухшаговую процедуру
# Считаем веса
p_hat_weight_2 <- sqrt(p_hat_weight * 
                         (1 - p_hat_weight) / 
                         group_n) * 
  grad(qt, p_hat_weight, df = df)

# Применяем МНК с весами
model_weight_2 <- lm(qt(p_hat, df) ~ X + 0, 
                     weights = p_hat_weight)

# Сравним предсказанные вероятности
p_hat_weight_2 <- pt(predict(model_weight_2), df)
rbind(p, p_hat, p_hat_lm, 
      p_hat_weight, p_hat_weight_2)

# Сравним коэффициенты
beta_weight_2 <- model_weight_2$coefficients
data.frame("LS" = beta_lm, 
           "LS Weights" = beta_weight,
           "LS Weights 2" = beta_weight_2,
           "True" = beta)

# ЗАДАНИЯ (* - непросто, ** - сложно, *** - брутально)
# 3.1.    Рассмотрите модели с альтернативными спецификациями:
#         1)    линейная
#         2)    нормальное распределение
#         3)    логистическое распределение
#         4)    экспоненциальное распределение
# 3.2.    Примените минимум хи-квадрат метод для оценивания
#         вероятности выжить на Титанике в зависимости от пола
#         пассажира и его класса (см. data("Titanic"))

#---------------------------------------------------
# Часть 4. Тестирование гипотез о вероятностях
#          и предельных эффектах
#---------------------------------------------------

# Пусть имеются два индивида:
# Борис
Boris <- data.frame("inc" = 0.5,                           # укажем характеристики
                    "pay" = 0.1,                           # Бориса в датафрейме
                    "age" = 0.3,
                    "ins" = 1,
                    "chl" = 1)
# Зинаида
Zina <- data.frame("inc" = 0.3,                            # укажем характеристики
                   "pay" = 0.2,                            # Зинаиды в датафрейме
                   "age" = 0.6,
                   "ins" = 0,
                   "chl" = 1)

# Оценим для них вероятности дефолта,
# используя оценки полной модели
# P(Борис терпит дефолт)
p.Boris <- predict(model.probit, 
                   type = "response", 
                   newdata = Boris)
# P(Зинаида терпит дефолт)
p.Zina <- predict(model.probit, 
                  type = "response", 
                  newdata = Zina)
# Разница вероятностей
p.diff <- p.Boris - p.Zina

# Пример №1. Проверим гипотезу о том, что вероятности
# дефолта для Бориса и Зинаиды совпадают
# H0: P(Борис терпит дефолт) = P(Зина терпит дефолт)
# Эквивалентная запись:
# H0: P(Борис терпит дефолт) - P(Зина терпит дефолт) = 0

# Будем использовать тест Вальда
# Проверяются гипотезы вида:
# H0: C(x) = 0
# Статистика теста:
# W = С(x)' * AsCov(C(x)) ^ (-1) * С(x), где:
# x - вектор параметров модели: в нашем 
#     случае beta
# C(x) - вектор столбец из функций, накладывающих
#        ограничения на параметры
# r - число ограничений, совпадающее с числом 
#     строк вектора столбца C(x)
# При верной H0 статистика теста W в асимптотике 
# имеет хи-квадрат распределение с r степенями свободы

# Напишем функцию, позволяющую
# дифференцировать вероятность успеха
# по коэффициентам
probGrad <- function(model,                                # объект, возвращаемый glm() 
                     newdata = NULL)                       # датафрейм, содержащий информацию об
{                                                          # индивидах, для которых оцениваются
  # вероятности
  beta.est <- coefficients(model)                          # оценки регрессионных коэффициентов
  m <- length(beta.est)                                    # число оцениваемых параметров
  
  if(!is.null(newdata))                                    # если не были поданы новые данные, то
  {                                                        # вероятности оцениваются для индивидов из
    model.formula <- model$formula                         # выборки, по которой оценивались параметры
    newdata[as.character(model.formula[[2]])] <- 1         # модели
    
    newdata <- model.frame(formula = model.formula,        # добавляем в датафрейм переменные, которые
                           data = newdata)                 # являются функциями от изначальных переменных
  }
  
  y.li.est <- predict(model,                               # оценка линейного индекса
                      newdata = newdata)
  y.li.d <- dnorm(y.li.est)                                # функция плотности в точке
  # линейного индекса
  
  X <- as.matrix(newdata[, -1])                            # создаем матрицу независимых переменных,
  # удаляя из нее зависимую переменную [, -1],
  X <- cbind(1, X)                                         # а затем добавляем константу    
  
  n <- nrow(X)                                             # число наблюдений
  
  my_grad <- matrix(NA, n, m)                              # матрица, в которой по строкам будут храниться
  # градиенты функции по каждой из вероятностей
  for(i in 1:m)                                            # для каждого из оцениваемых параметров
  {                                                        # рассчитываем частные производные вероятностей
    my_grad[, i] <- X[, i] * y.li.d                        # по beta и рассчитываем значения градиента
  }
  
  colnames(my_grad) <- c("Intercept",                      # для удобства добавляем имена для
                         colnames(newdata[, -1]))          # столбцов градиента
  
  return(my_grad)                                          # возвращаем градиент
}

# Рассчитаем градиенты вероятностей дефолта
# для Бориса и Зинаиды, а также для разности
# соответствующих вероятностей
pg.Boris <- probGrad(model.probit, Boris)                  # градиент по вероятности Бориса
pg.Zina <- probGrad(model.probit, Zina)                    # градиент по вероятности Зинаиды
pg.diff <- pg.Boris - pg.Zina                              # градиент разности вероятностей
# дефолта Бориса и Зинаиды как
# разность градиентов
# Посчитаем оценки асимптотической дисперсий
# разницы вероятностей дефолта Бориса и Зиниды
as.cov.beta <- vcov(model.probit)                          # достаем оценку асимптотической ковариационной
# матрицы оценок регрессионных коэффициентов
as.cov.pg.diff <- pg.diff %*% as.cov.beta %*% t(pg.diff)   # считаем оценку асимптотической дисперсии
# оценки разности вероятностей

# Рассчитаем тестовую статистику
W.stat <- p.diff * solve(as.cov.pg.diff) * p.diff          # статистика теста Вальда
p.value <- 1 - pchisq(W.stat, df = 1)                      # p-value теста Вальда

# Пример №2. Проверим гипотезу:
# H0: P(Борис терпит дефолт) = P(Зина терпит дефолт)
#     P(Владимир терпит дефолт) = 0.82
# Эквивалентная запись:
# H0: P(Борис терпит дефолт) - P(Зина терпит дефолт) = 0
#     P(Владимир терпит дефолт) - 0.82 = 0

# Добавим Владимира
Vlad <- data.frame("inc" = 0.9,                            # укажем характеристики
                   "pay" = 0.7,                            # Владимира в датафрейме
                   "age" = 0.2,
                   "ins" = 1,
                   "chl" = 0)

p.Vlad <- predict(model.probit,                            # вычисляем вероятность
                  type = "response",                       # занятости Владимира
                  newdata = Vlad)

pg.Vlad <- probGrad(model.probit, Vlad)                    # рассчитываем градиент вероятности
# занятости Владимира по оцениваемым
# параметрам

# Создадим вектор вида C(x)
p_new <- matrix(c(p.diff, p.Vlad - 0.82), ncol = 1)

# Расчитаем оценки асимптотической ковариационной
# матрицы ограничений
pg_new <- rbind(pg.diff,                                   # матрица, по строкам которой 
                pg.Vlad)                                   # расположены градиенты ограничений,
# то есть Якобиан
as.cov.pg.new <- pg_new %*% as.cov.beta %*% t(pg_new)      # оцениваем асимптотическую 
# ковариационную матрицу ограничений

# Рассчитаем тестовую статистику
W.stat <- t(p_new) %*% solve(as.cov.pg.new) %*% p_new      # статистика теста Вальда
p.value <- 1 - pchisq(W.stat, df = 2)                      # p-value теста Вальда

# Тестирование гипотез о предельных 
# эффектах осуществляется по аналогии

# Использование теста Вальда в данном случае позволило
# нам не искать максимум функции правдоподобия при
# сложном нелинейном ограничении

# ЗАДАНИЯ (* - непросто, ** - сложно, *** - брутально)
# 4.1.    Проверьте гипотезу о том, что:
#         1)    вероятность дефолта Бориса и Влада
#               одинакова
#         2)    вероятность дефолта Бориса на 10% 
#               больше, чем у Владимира
#         3)    вероятность занятости Бориса на 10% 
#               больше, чем у Владимира, а вероятность
#               дефолта Зины составляет 0.5
# 4.2.    Создайте еще двух индивидов и проверьте гипотезу
#         о том, что:
#         1*)   вероятности занятости у всех пяти индивидов
#               совпадают
#         2*)   вероятность занятости у ваших двух индивидов 
#               в сумме больше, чем вероятность занятости Бориса